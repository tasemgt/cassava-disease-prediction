{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3b95ccd-e469-466a-9552-c47cf0187f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnxruntime\n",
    "# !pip install ImageIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ca438c-1761-4157-98bb-0fcd83e5ceb8",
   "metadata": {},
   "source": [
    "### Smoke Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cbdcdbe-9e34-4c6a-bb3e-9310fc905801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from imageio.v3 import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b9e3f-b3ea-454c-8eb0-029c2f670717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47808134-ea70-439d-be2f-18d7a9f3ed02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference OK, output shape: (1, 5)\n"
     ]
    }
   ],
   "source": [
    "sess = ort.InferenceSession(\"./artefacts/models/onnx/model.onnx\")\n",
    "\n",
    "x = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
    "y = sess.run(None, {sess.get_inputs()[0].name: x})\n",
    "\n",
    "print(\"Inference OK, output shape:\", y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae792051-92e1-4da8-9828-3d15ecce5c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff2cc8b9-4ced-4810-aa17-6f6480001b91",
   "metadata": {},
   "source": [
    "### Inference on Real Cassava Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f3d1024-4003-4fc6-b6d8-01a550a4f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- CONFIG ----\n",
    "MODEL_PATH = \"./artefacts/models/model.onnx\"\n",
    "IMAGE_PATH = \"./data/train/cbb/train-cbb-2.jpg\" #\"./data/test/0/test-img-52.jpg\"          # path to a test image\n",
    "IMG_SIZE = 224                     # change if needed\n",
    "MEAN = [0.485, 0.456, 0.406]       # ImageNet mean\n",
    "STD = [0.229, 0.224, 0.225]        # ImageNet std\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b10715d-c8f0-4240-9e02-1ca5a4fbb6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    img = np.array(img).astype(np.float32) / 255.0\n",
    "    img = (img - MEAN) / STD           # normalize\n",
    "    img = np.transpose(img, (2, 0, 1)) # HWC â†’ CHW\n",
    "    img = np.expand_dims(img, axis=0)  # batch dim\n",
    "\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27f1b1bb-3b4b-4b8e-9c1e-f9b6df659ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Create ONNX Runtime session\n",
    "    session = ort.InferenceSession(\n",
    "        MODEL_PATH,\n",
    "        providers=[\"CPUExecutionProvider\"]\n",
    "    )\n",
    "\n",
    "    # Inspect model inputs / outputs\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "\n",
    "    print(f\"Input name: {input_name}\")\n",
    "    print(f\"Output name: {output_name}\")\n",
    "\n",
    "    # Preprocess input\n",
    "    x = preprocess_image(IMAGE_PATH)\n",
    "\n",
    "    # Run inference\n",
    "    outputs = session.run(\n",
    "        [output_name],\n",
    "        {input_name: x}\n",
    "    )\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    print(\"Output shape:\", logits.shape)\n",
    "    print(\"Raw output:\", logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f5dd905-7fcc-4d37-8395-31f4ccb23f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input name: input\n",
      "Output name: output\n",
      "Output shape: (1, 5)\n",
      "Raw output: [[5.30851925e-12 9.99999881e-01 1.29559226e-08 1.16865266e-07\n",
      "  1.49033962e-11]]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5a23a-53f3-4573-9e95-f1f0a27be23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3bd0d6c-7cd0-45a9-b0c3-5a0f705fd86f",
   "metadata": {},
   "source": [
    "### Using Class based solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a90da0-a3ec-4844-b9ca-cfb0ea642bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaONNXClassifier:\n",
    "    def __init__(self, model_path=\"./artefacts/models/model.onnx\"):\n",
    "        self.session = ort.InferenceSession(\n",
    "            model_path,\n",
    "            providers=[\"CPUExecutionProvider\"]\n",
    "        )\n",
    "        self.input_name = self.session.get_inputs()[0].name\n",
    "\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((224, 224)),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    " \n",
    "        self.class_map = {\n",
    "            0: \"cbsd\",\n",
    "            1: \"cbb\",\n",
    "            2: \"cmd\",\n",
    "            3: \"cgm\",\n",
    "            4: \"healthy\"\n",
    "        }\n",
    "\n",
    "    # ----------------------\n",
    "    # PREPROCESS\n",
    "    # ----------------------\n",
    "    def preprocess(self, data):\n",
    "        data = data[0]\n",
    "        image_bytes = bytes(data[\"body\"])\n",
    "\n",
    "        # Read image -> HWC, uint8\n",
    "        img = imread(image_bytes)\n",
    "\n",
    "        # Convert to float tensor\n",
    "        img = torch.from_numpy(img).float() / 255.0  # HWC\n",
    "\n",
    "        # Convert to CHW\n",
    "        img = img.permute(2, 0, 1)  # CHW\n",
    "\n",
    "        # Resize + normalize\n",
    "        img = self.transform(img)\n",
    "\n",
    "        # Add batch dimension\n",
    "        img = img.unsqueeze(0)  # [1, 3, 224, 224]\n",
    "\n",
    "        # Convert to NumPy and float32 for ONNX\n",
    "        return img.numpy().astype(np.float32)\n",
    "\n",
    "    # ----------------------\n",
    "    # INFERENCE\n",
    "    # ----------------------\n",
    "    def infer(self, input_tensor):\n",
    "        outputs = self.session.run(\n",
    "            None,\n",
    "            {self.input_name: input_tensor}\n",
    "        )\n",
    "        return outputs[0]\n",
    "\n",
    "    # ----------------------\n",
    "    # POSTPROCESS\n",
    "    # ----------------------\n",
    "    def postprocess(self, outputs):\n",
    "        class_idx = outputs.argmax(axis=-1)[0]\n",
    "        print(\"Predicted class index:\", class_idx)\n",
    "        return f\"Predicted Class: {self.class_map[class_idx]}\"\n",
    "\n",
    "    # ----------------------\n",
    "    # FULL PIPELINE\n",
    "    # ----------------------\n",
    "    def predict(self, data):\n",
    "        x = self.preprocess(data)\n",
    "        y = self.infer(x)\n",
    "        print(\"Raw model output:\", y)\n",
    "        return self.postprocess(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c1a24-0f46-4df7-a6c7-a2178c802b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a8ab528-8c87-48d9-87e1-a7e76dded3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw model output: [[1.5660039e-07 6.8009138e-01 3.1492212e-01 4.9860552e-03 2.2393111e-07]]\n",
      "Predicted class index: 1\n",
      "Predicted Class: cbb\n"
     ]
    }
   ],
   "source": [
    "classifier = CassavaONNXClassifier(model_path=\"./artefacts/models/onnx/model.onnx\")\n",
    "\n",
    "# Example raw input (simulate the same input dict format)\n",
    "data_path = \"./data/train/cgm/train-cgm-10.jpg\" #\"./data/test/0/test-img-19.jpg\"\n",
    "with open(data_path, \"rb\") as f:\n",
    "    data = [{\"body\": f.read()}]\n",
    "\n",
    "predictions = classifier.predict(data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c7760-319d-4665-abfd-cfc74bf06f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d72525-bc6a-4116-9424-a22d144d398e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97197e1e-6ae6-48f6-ba9e-6e6ddedc38c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
